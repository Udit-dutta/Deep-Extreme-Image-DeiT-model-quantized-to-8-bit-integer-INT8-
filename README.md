# Deep-Extreme-Image-DeiT-model-quantized-to-8-bit-integer-INT8
This project aims to evaluate the performance of a Deep Extreme Image (DeiT) model quantized to 8-bit integer (INT8) precision compared to its 32-bit floating-point (FP32) counterpart. The evaluation focuses on inference speed (measured in FPS) and, hypothetically, accuracy (measured by Average Precision - AP)
